The goal: Adding custom method inside spider

Docs Spider: 
https://docs.scrapy.org/en/latest/topics/spiders.html

Class <spidername>(scrapy.Spider):
    name = str(<name spider>) # Name of spider
    allowed_domains = list(<allowed_domains>) # the domain that allowed for spider to access.
    start_urls = list(<urls>) # The starting url for scraping.

    # NOTE: We can add custom method. This method help to modify built-in method.

    def start_requests(self):
    # Note:
    # - If this function exist, scrapy will run this function. if it is not it will work of the link inside 'start_urls' variable.
    # - This method must return an iterable with the first Requests to crawl for this spider. 
    # - It is called by Scrapy when the spider is opened for scraping. 
    # - Scrapy calls it only once, so it is safe to implement start_requests() as a generator.
    pass


    def parse(self, response):
    # Note: 
    # - The parse method is in charge of processing the response and returning scraped data and/or more URLs to follow.
    # - This is built-in method
    # - This is the default callback used by Scrapy to process downloaded responses, when their requests donâ€™t specify a callback.
    # - It must return a Request object, an item object, an iterable of Request objects and/or item objects, or None.
    pass

    def custom_method(self, response):
    """Getting some response data in here. It help debugging if we split process into multiple method"""