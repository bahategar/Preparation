{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "770b64d6-bde3-4586-8e50-240c60fcaabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import json\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, TrainingArguments, AutoModelForSequenceClassification, Trainer\n",
    "from torchinfo import summary\n",
    "from datasets import load_dataset\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c39c1c1-0d34-4c29-bdf8-b6cb5a0bdd66",
   "metadata": {},
   "source": [
    "![flow-model-requirement](images/Flow-min-requirement-Training-FineTuning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cb819b-e0ef-4e47-920a-13220432429b",
   "metadata": {},
   "source": [
    "# Tokenizer Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "745520b1-db9f-4e28-a18d-dcb8971ecf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = 'bert-base-uncased'\n",
    "checkpoint = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d2526cf-ead8-44c5-97b7-bf21c11b6211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function for tokenizing the dataset\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch['sentence'], truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572420f8-b374-408d-bd76-d2f8589dc0c0",
   "metadata": {},
   "source": [
    "# Load Dataset and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c9d05a-eb40-4949-b656-7cb8dd56ac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset('glue', 'sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d1f963d-d0c6-4ba0-8f7b-23849b10d12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "618d3181-32a1-419b-bf58-e60200b39c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': ['hide new secretions from the parental units ',\n",
       "  'contains no wit , only labored gags ',\n",
       "  'that loves its characters and communicates something rather beautiful about human nature '],\n",
       " 'label': [0, 0, 1],\n",
       " 'idx': [0, 1, 2]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de940c8a-a0a3-4513-8a09-e3c2d83cba3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525f20b55383449eb805cecb863e686a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "013443d6-dfd9-451d-8eb0-1f97a7be7197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6694d4d2-13ad-4c30-ab00-40154adb3f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': ['hide new secretions from the parental units ',\n",
       "  'contains no wit , only labored gags ',\n",
       "  'that loves its characters and communicates something rather beautiful about human nature '],\n",
       " 'label': [0, 0, 1],\n",
       " 'idx': [0, 1, 2],\n",
       " 'input_ids': [[101, 5342, 2047, 3595, 8496, 2013, 1996, 18643, 3197, 102],\n",
       "  [101, 3397, 2053, 15966, 1010, 2069, 4450, 2098, 18201, 2015, 102],\n",
       "  [101,\n",
       "   2008,\n",
       "   7459,\n",
       "   2049,\n",
       "   3494,\n",
       "   1998,\n",
       "   10639,\n",
       "   2015,\n",
       "   2242,\n",
       "   2738,\n",
       "   3376,\n",
       "   2055,\n",
       "   2529,\n",
       "   3267,\n",
       "   102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85b8abf-97b4-4524-ae5a-41ed9b3ba9ea",
   "metadata": {},
   "source": [
    "# Training Arguments Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ff5692b-acc1-41a5-975f-cde965141e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='trainer_demo',\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    num_train_epochs=1,\n",
    "    report_to='none',\n",
    "    fp16=True,  # Enable mixed-precision training if your GPU supports it\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd078e48-1275-46a2-a4bb-3b442cc32e6c",
   "metadata": {},
   "source": [
    "# Main Model for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22968d85-765d-452d-aa5f-132d45480c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291e36045db847d49d130a0661c462d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baha Tegar\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Baha Tegar\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9afa1e1-3b3d-4cbf-97d6-4aa13d1526bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "DistilBertForSequenceClassification                     --\n",
       "├─DistilBertModel: 1-1                                  --\n",
       "│    └─Embeddings: 2-1                                  --\n",
       "│    │    └─Embedding: 3-1                              23,440,896\n",
       "│    │    └─Embedding: 3-2                              393,216\n",
       "│    │    └─LayerNorm: 3-3                              1,536\n",
       "│    │    └─Dropout: 3-4                                --\n",
       "│    └─Transformer: 2-2                                 --\n",
       "│    │    └─ModuleList: 3-5                             42,527,232\n",
       "├─Linear: 1-2                                           590,592\n",
       "├─Linear: 1-3                                           1,538\n",
       "├─Dropout: 1-4                                          --\n",
       "================================================================================\n",
       "Total params: 66,955,010\n",
       "Trainable params: 66,955,010\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe1c497-ae50-4dc4-a0d5-92e1566c4227",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d4418dc-ef1c-4514-a648-7dbd83d2c840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # Should return True if a compatible GPU is detected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db5ecfd9-c24b-47e1-b316-90d74c01e70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# After defining the trainer, before starting the training\n",
    "print(\"Model device:\", next(model.parameters()).device)  # Should output \"cuda\" if on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71332d3f-6f65-4ee2-b7ad-f9a1b8ed03f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "params_before = []\n",
    "for name, p in model.named_parameters():\n",
    "    params_before.append(p.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e8b5db5-3de7-4ef0-9ed6-5687daec0602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation metrics function\n",
    "# It helps to evaluate performance model per epochs.\n",
    "\n",
    "def compute_metrics(logits_and_labels):\n",
    "    logits, labels = logits_and_labels\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc3eb519-a087-4a86-8f5d-4ce9cfa3465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Trainer Object\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf458895-bfff-41d9-87f7-1e44082c9fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8419' max='8419' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8419/8419 10:12, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.392657</td>\n",
       "      <td>0.903670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8419, training_loss=0.16742661396048814, metrics={'train_runtime': 612.663, 'train_samples_per_second': 109.928, 'train_steps_per_second': 13.742, 'total_flos': 517212489917652.0, 'train_loss': 0.16742661396048814, 'epoch': 1.0})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33404e6d-3af2-495a-bdac-cb928e84eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Manually evaluation model\n",
    "# metric = evaluate.load('accuracy')\n",
    "\n",
    "# predictions = trainer.predict(tokenized_datasets['validation'])\n",
    "# logits, labels = predictions.predictions, predictions.label_ids\n",
    "\n",
    "# accuracy = metric.compute(predictions=np.argmax(logits, axis=-1), references=labels)\n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a154a16e-e9dd-40df-9db0-96b2f979783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# trainer.save_model('model_demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "563d7fc2-cba1-4811-82de-a9f22f43780b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27883.146\n",
      "161.08818\n",
      "2.7293258\n",
      "1.986839\n",
      "2232.5437\n",
      "2.6709063\n",
      "2213.6782\n",
      "1.9484951\n",
      "2012.0284\n",
      "1.753175\n",
      "1948.2728\n",
      "1.3667009\n",
      "2.744045\n",
      "1.3348948\n",
      "8460.632\n",
      "9.250202\n",
      "7858.458\n",
      "1.0969527\n",
      "2.6402593\n",
      "1.2763145\n",
      "2163.956\n",
      "2.404458\n",
      "2154.2632\n",
      "1.6051614\n",
      "1961.2778\n",
      "1.380275\n",
      "1899.1196\n",
      "1.1958301\n",
      "2.800476\n",
      "1.2029843\n",
      "8395.897\n",
      "8.556961\n",
      "7781.2656\n",
      "1.0476208\n",
      "2.5595791\n",
      "1.3969865\n",
      "2143.835\n",
      "2.6230874\n",
      "2156.0964\n",
      "1.7447972\n",
      "1924.1206\n",
      "1.239581\n",
      "1907.9014\n",
      "1.15749\n",
      "2.7441812\n",
      "1.262913\n",
      "8444.629\n",
      "9.246374\n",
      "7612.789\n",
      "1.1211011\n",
      "2.3512888\n",
      "1.0532508\n",
      "2134.5413\n",
      "2.2581916\n",
      "2151.4163\n",
      "1.7893755\n",
      "1934.0452\n",
      "1.189076\n",
      "1861.9167\n",
      "1.3203943\n",
      "2.5234005\n",
      "1.3941909\n",
      "8302.032\n",
      "9.428415\n",
      "7296.802\n",
      "1.3004622\n",
      "2.1989338\n",
      "1.0753925\n",
      "2038.1344\n",
      "2.4453697\n",
      "2019.7267\n",
      "1.1392417\n",
      "1721.0021\n",
      "1.2407024\n",
      "1686.5559\n",
      "1.885263\n",
      "2.2727752\n",
      "1.7646315\n",
      "7594.2646\n",
      "9.256289\n",
      "6494.3145\n",
      "1.8898032\n",
      "2.2399554\n",
      "1.8041012\n",
      "1871.8185\n",
      "2.3218775\n",
      "1886.4762\n",
      "0.84884477\n",
      "1564.0212\n",
      "2.348853\n",
      "1577.3542\n",
      "2.3680573\n",
      "2.5383296\n",
      "2.599451\n",
      "6691.4673\n",
      "9.455466\n",
      "6277.17\n",
      "2.1716945\n",
      "4.818941\n",
      "1.4956582\n",
      "1526.9487\n",
      "1.726846\n",
      "4.4161253\n",
      "0.0009723905\n"
     ]
    }
   ],
   "source": [
    "# Do sanity Check\n",
    "params_after = []\n",
    "for name, p in model.named_parameters():\n",
    "  params_after.append(p.detach().cpu().numpy())\n",
    "\n",
    "for p1, p2 in zip(params_before, params_after):\n",
    "  print(np.sum(np.abs(p1 - p2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1468b03-76af-4520-a4ee-b21f8332be00",
   "metadata": {},
   "source": [
    "# Fix Naming Label Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9fd62123-23e6-48f5-9587-adf4b5c87243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_path = './model_demo/config.json'\n",
    "# with open(config_path) as f:\n",
    "#     j = json.load(f)\n",
    "#     print(\"Before updated:\")\n",
    "#     print(j)\n",
    "\n",
    "#     # Add 'id2label' for determine the label name\n",
    "#     j['id2label'] = {0: 'negative', 1: 'positive'}\n",
    "\n",
    "#     with open(config_path, 'w') as f:\n",
    "#         json.dump(j, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "99b13cd6-1a8a-4679-8f9a-e314a637c475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_name_or_path': 'distilbert-base-uncased', 'activation': 'gelu', 'architectures': ['DistilBertForSequenceClassification'], 'attention_dropout': 0.1, 'dim': 768, 'dropout': 0.1, 'hidden_dim': 3072, 'initializer_range': 0.02, 'max_position_embeddings': 512, 'model_type': 'distilbert', 'n_heads': 12, 'n_layers': 6, 'pad_token_id': 0, 'problem_type': 'single_label_classification', 'qa_dropout': 0.1, 'seq_classif_dropout': 0.2, 'sinusoidal_pos_embds': False, 'tie_weights_': True, 'torch_dtype': 'float32', 'transformers_version': '4.44.2', 'vocab_size': 30522, 'id2label': {'0': 'negative', '1': 'positive'}}\n"
     ]
    }
   ],
   "source": [
    "# # Cross check\n",
    "# with open(config_path) as f:\n",
    "#     j = json.load(f)\n",
    "\n",
    "# print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f58b80d-3090-4fc9-812d-8a522622ee3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
