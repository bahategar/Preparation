(1) Complexity classes and estimating efficiency:
	1 < log (n) < Sqrt(n) < n < n log(n) < n^2 < n^3 < 2^n < n!
	
	The common cases:
	(a) O(1) -> The running time of a constant-time algorithm does not depend on the input size.
	(b) O(log n) -> The algorithm that works by dividing the input size. Common case is we divide the input size, and select which group to focus on.

	(c) O(sqrt(n)) -> The algorithm works by evaluate all the input size but only square root of the input size.

	(d) O(n) -> The algorithm works by going through all the input.
	(e) O(n log(n)) -> The algorithm works by dividing input size, select which group to focus on, then going through to all the choosen group input.
	(f) O(n^2) -> The algorithm works by doing two nested loops
	(g) O(n^3) -> The algorithm works by doing three nested loops.
	(h) O(2^n) -> The algorithm works by going through all the subset of input elements.
			NOTE: Remember the power set in mathematics
	(f) O(n!) -> The algorithm works by going through all the permutations of the input elements.


Square root time complexity means that the algorithm requires O(N^(1/2)) evaluations where the size of input is N.

	Input size	Required time complexity
	-----------------------------------------
	  n <= 10	  O(n!)
	  n <= 20	  O(2^n)
	  n <= 500	  O(n^3)
	  n <= 5000	  O(n^2)
	  n <= 10^6	  O(nlog n) or O(n)
	  n is large	  O(1) or O(log n)
	

(2) Common cases:
- Loops
  (i) Time complexity O(n) -> When the iteration variable increases/decreases arithmetically 
	 and iteration variable = boundary variable.
  (a) Case 1
	'''
	for(let i = 0; i < n; i++) {
	    <statements>
	}
	'''

	ANALYSIS:
	- For boundary: i < n,

    	  time |  i
	-------------
	   1	  0
	   2	  1
	   3	  2
	   4	  3
	  ...	 ...
	   t	 (n-1)

          Then, t = (n-1) = O(n).

	Some similar cases:
	  '''

	  let i = 0
	  while i < n {
	    i++
	    <statements>
	  }

	  '''

  (ii) Time complexity O(sqrt(n)) -> When the iteration variable increase/decrease arithmetically but
	the boundary variable increase/decrease neither arithmetically nor gemoetrically.

	'''
	let p = 0; // boundary variable.
	for(let i = 0; p < n; i++) { // i is iteration variable.
	    p = p + i;
	    <statements>
	}
	'''

	ANALYSIS:
	- For boundary: p < n,

    	  time |  p
	-------------
	   1	  0 
	   2	  1 => 0 + 1
	   3	  3 => 0 + 1 + 2
	   4	  6 => 0 + 1 + 3
	  ...	  ...
	   t	  0 + 1 + 3 + ... + t = (t^2 - t) / 2

          When p -> n, then n -> (t^2 - t) / 2, or we could say n ~ t^2.
	  Then, t = O(sqrt(n)).

	Some similar cases:
	  '''

	  for(let i = 0; i*i < n; i++) {
	      <statements>
	  }

	  '''
	  '''

	  let i = 1;
	  let k = 1;
	  while (k < n) {
	      <statements>
	      k = k + i;
	      i ++;
	  }

	  '''

  (iii) Time complexity O(sqrt(n)) -> When the iteration variable increases/decreases geometrically 
	 and iteration variable = boundary variable.

	'''
	for(let i = 1; i < n; i = c * i) {
	    <statements>
	}
	'''

	ANALYSIS:
	- For boundary: i < n,

    	  time |  i
	-------------
	   1	  1 
	   2	  c 
	   3	  c^2 
	   4	  c^3 
	  ...	  ...
	   t	  c^(t-1)

          When i -> n, then i -> c^(t-1) or we could say t = logc (n) + 1. 
	  Then, t = O( log(n) ).

	Some similar cases:
	  '''
	  let i = 1;
	  for(let i=0; i >= 1; i = i / c) {
	    <statements>
	  }

	  '''
	  '''
	  let i = 1;
	  while (i < n) {
	    i = c * i;
	    <statements>
	  }

	  '''
	  '''
	  let i = n;
	  while (i >= 1) {
	    i = i / c;
	    <statements>
	  }

	  '''

- Nesting -> For nesting, we only need to multiply the time complexity of each component.

  	'''
	for (let i=1; i <= n; i++) {
           for (let j=1; j <= n; j++) {
		<statements>
	   }
	}
	'''

	ANALYSIS:
	Time complexity outer loop = O(n)
	Time complexity inner loop = O(n)
	Total time complexity = O(n^2)


- Phases -> For each phases, we only need to choose the bottle neck.
  	'''

	for(let i = 0; i < n; i++) {
	    <statements>
	}

	for (let i=1; i <= n; i++) {
           for (let j=1; j <= n; j++) {
		<statements>
	   }
	}

	for(let i = 0; i < n; i++) {
	    <statements>
	}
	'''

	ANALYSIS:
	Time complexity first loop = O(n)
	Time complexity second loop = O(n^2) -> The bottle neck.
	Time complexity third loop = O(n)
	The total time complexity = O(n^2)

- Recursion -> a. The function calls itself to break the problems into sub-problems (untill reach its base condition) and then solve each sub-problem.
	       b. The time complexity of each call is O(1). 
		  If a function calls itself two times then its time complexity is O(2^N)
		  If it calls three times then its time complexity is O(3^N) and so on.

  	'''
	function g(n) {
	  if (n == 1) return;
	  g(n - 1);
	  g(n - 1);
	}
	'''

	ANALYSIS:

    	  function call |  number of calls
	  ---------------------------------
		g(n)		1
	   	g(n - 1)	2
		g(n - 2)	4
		  ...           ...
		g(1)		2^(n-1)

	  Based on that, the time complexity is: 1 + 2 + 4 + ... + 2^(n-1) = 2^n - 1 = O(2^n)
