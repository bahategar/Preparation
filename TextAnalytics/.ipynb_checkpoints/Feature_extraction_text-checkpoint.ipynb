{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef832396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contractions import CONTRACTION_MAP\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1eb246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS = [\n",
    "'the sky is blue',\n",
    "'sky is blue and sky is beautiful',\n",
    "'the beautiful sky is so blue',\n",
    "'i love blue cheese'\n",
    "]\n",
    "\n",
    "new_doc = ['loving this blue sky today']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26743006",
   "metadata": {},
   "source": [
    "# Bag of Words Model\n",
    "\n",
    "> Convert text documents into vectors that represents the frequency of all its distinct words, disregarding their order.\n",
    "\n",
    "NOTE: \n",
    "- We can make it an n-gram Bag of Words model such that the vector represent the frequency of distinct n-gram.\n",
    "\n",
    "Understanding N-grams\n",
    "- Unigram: A single word. For example, in the sentence \"the cat sat on the mat,\" the unigrams are [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"].\n",
    "- Bigram: A sequence of two consecutive words. For example, in the same sentence, the bigrams are [\"the cat\", \"cat sat\", \"sat on\", \"on the\", \"the mat\"].\n",
    "- Trigram: A sequence of three consecutive words. For example, the trigrams are [\"the cat sat\", \"cat sat on\", \"sat on the\", \"on the mat\"]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c02a4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 1 0 1 0 1]\n",
      " [1 1 1 0 2 0 2 0 0]\n",
      " [0 1 1 0 1 0 1 1 1]\n",
      " [0 0 1 1 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def bow_extractor(corpus, ngram_range=(1,1)):\n",
    "    vectorizer = CountVectorizer(min_df=1, ngram_range=ngram_range)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features\n",
    "\n",
    "# build bow vectorizer and get features\n",
    "bow_vectorizer, bow_features = bow_extractor(CORPUS)\n",
    "features = bow_features.todense()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d858cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# extract features from new document using built vectorizer\n",
    "new_doc_features = np.array(bow_vectorizer.transform(new_doc).todense())\n",
    "print(new_doc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27c2dacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and' 'beautiful' 'blue' 'cheese' 'is' 'love' 'sky' 'so' 'the']\n"
     ]
    }
   ],
   "source": [
    "# print feature names\n",
    "\n",
    "feature_names = bow_vectorizer.get_feature_names_out()\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "027948a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>blue</th>\n",
       "      <th>cheese</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>sky</th>\n",
       "      <th>so</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  beautiful  blue  cheese  is  love  sky  so  the\n",
       "0    0          0     1       0   1     0    1   0    1\n",
       "1    1          1     1       0   2     0    2   0    0\n",
       "2    0          1     1       0   1     0    1   1    1\n",
       "3    0          0     1       1   0     1    0   0    0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display features as dataframe\n",
    "import pandas as pd\n",
    "\n",
    "def display_features(features, feature_names):\n",
    "    df = pd.DataFrame(data=features,\n",
    "                      columns=feature_names)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "display_features(features, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af88348a",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "\n",
    "There are two components:\n",
    "- Term Frequency (tf) => Frequency of a \"term\" in a particular document.\n",
    "\n",
    "NOTE: Term frequency is computed in the Bag of Words model. It can be normalization or raw frequency form.\n",
    "\n",
    "- Inverse Document Frequency (idf) => Logarithmic of total number of documents in our corpus per frequency of document (df) that contains the term.\n",
    "\n",
    "NOTE: (1) Some people modify the idf by adding 1 to the document frequency to prevent division-by-zero, (2) Adding 1 to the idf to avoid zero idf, (3) It can be normalize form by dividing it with its Euclidean norm.\n",
    "\n",
    "- TF-IDF = tf x idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f9ad5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>blue</th>\n",
       "      <th>cheese</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>sky</th>\n",
       "      <th>so</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    and  beautiful  blue  cheese    is  love   sky    so   the\n",
       "0  0.00       0.00  0.40    0.00  0.49  0.00  0.49  0.00  0.60\n",
       "1  0.44       0.35  0.23    0.00  0.56  0.00  0.56  0.00  0.00\n",
       "2  0.00       0.43  0.29    0.00  0.35  0.00  0.35  0.55  0.43\n",
       "3  0.00       0.00  0.35    0.66  0.00  0.66  0.00  0.00  0.00"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "\n",
    "def tfidf_transformer(bow_matrix):\n",
    "    transformer = TfidfTransformer(norm='l2',\n",
    "                                   smooth_idf=True,\n",
    "                                   use_idf=True)\n",
    "    \n",
    "    tfidf_matrix = transformer.fit_transform(bow_matrix)\n",
    "    return transformer, tfidf_matrix\n",
    "\n",
    "# build tfidf transformer and show train corpus tfidf features\n",
    "\n",
    "tfidf_trans, tdidf_features = tfidf_transformer(bow_features)\n",
    "features = np.round(tdidf_features.todense(), 2)\n",
    "feature_names = bow_vectorizer.get_feature_names_out()\n",
    "display_features(features, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2eccd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>blue</th>\n",
       "      <th>cheese</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>sky</th>\n",
       "      <th>so</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  beautiful  blue  cheese   is  love   sky   so  the\n",
       "0  0.0        0.0  0.63     0.0  0.0   0.0  0.77  0.0  0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show tfidf features for new_doc using built tfidf transformer\n",
    "\n",
    "nd_tfidf = tfidf_trans.transform(new_doc_features)\n",
    "nd_features = np.round(nd_tfidf.todense(), 2)\n",
    "display_features(nd_features, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3912ca1",
   "metadata": {},
   "source": [
    "# Advanced Word Vectorization Models\n",
    "\n",
    "Some advance word vectorization models:\n",
    "- TF-IDF Weighted Averaged Word Vectors\n",
    "- SpaCy Tokenizer\n",
    "- BERT Tokenizer\n",
    "- Byte Pair Encoding (BPE) Tokenizer\n",
    "- SentencePiece Tokenizer\n",
    "- GPT-3 Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dfda55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
