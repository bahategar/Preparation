{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e787b3ef",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5f5b69ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "24b91e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 781.4+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all the people who have seen this wonde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I recently bought the DVD, forgetting just how...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "1  OK... so... I really like Kris Kristofferson a...          0\n",
       "2  ***SPOILER*** Do not read this, if you think a...          0\n",
       "3  hi for all the people who have seen this wonde...          1\n",
       "4  I recently bought the DVD, forgetting just how...          0"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/movie_data.csv', encoding='utf-8')\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "1b0d7e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.iloc[1001:2000]\n",
    "df = df.iloc[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e64119c",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ba8b64d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:45: DeprecationWarning: invalid escape sequence '\\)'\n",
      "<>:46: DeprecationWarning: invalid escape sequence '\\W'\n",
      "<>:45: DeprecationWarning: invalid escape sequence '\\)'\n",
      "<>:46: DeprecationWarning: invalid escape sequence '\\W'\n",
      "C:\\Users\\Baha Tegar\\AppData\\Local\\Temp\\ipykernel_29832\\3115096720.py:45: DeprecationWarning: invalid escape sequence '\\)'\n",
      "  emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
      "C:\\Users\\Baha Tegar\\AppData\\Local\\Temp\\ipykernel_29832\\3115096720.py:46: DeprecationWarning: invalid escape sequence '\\W'\n",
      "  text = (re.sub('[\\W]+', ' ', text.lower()) +\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from pattern.en import tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = nltk.word_tokenize(text) \n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "def pos_tag_text(text):\n",
    "    \n",
    "    def penn_to_wn_tags(pos_tag):\n",
    "        if pos_tag.startswith('J'):\n",
    "            return wn.ADJ\n",
    "        elif pos_tag.startswith('V'):\n",
    "            return wn.VERB\n",
    "        elif pos_tag.startswith('N'):\n",
    "            return wn.NOUN\n",
    "        elif pos_tag.startswith('R'):\n",
    "            return wn.ADV\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    tagged_text = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    tagged_lower_text = [(word.lower(), penn_to_wn_tags(pos_tag))\n",
    "                         for word, pos_tag in\n",
    "                         tagged_text]\n",
    "    return tagged_lower_text\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    tokens = tokenize_text(text)\n",
    "    filtered_tokens = [token for token in tokens if token not in STOPWORDS]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "def remove_html_emoji(text):\n",
    "    # Remove html\n",
    "    text = re.sub('<[^>]*', '', text)\n",
    "    # Remove emoji\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
    "            ' '.join(emoticons).replace('-', ''))\n",
    "    return text\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \n",
    "    pos_tagged_text = pos_tag_text(text)\n",
    "    lemmatized_tokens = [wnl.lemmatize(word, pos_tag) if pos_tag\n",
    "                         else word                     \n",
    "                         for word, pos_tag in pos_tagged_text]\n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "    return lemmatized_tokens\n",
    "\n",
    "def filter_text(text):\n",
    "    \n",
    "    # Tokenize and get pos words\n",
    "    pos_words = pos_tag_text(text)\n",
    "    \n",
    "    processed_words = set()\n",
    "    \n",
    "    for word, tag in pos_words:\n",
    "        if (tag == 'n') or (tag == 'J'):\n",
    "            if len(word) > 3:\n",
    "                \n",
    "                word = wnl.lemmatize(word)\n",
    "                \n",
    "                processed_words.add(word)\n",
    "    \n",
    "    return list(processed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "491719f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brazil']"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data cleansing\n",
    "\n",
    "def preprocessor(text):\n",
    "    # Remove html emoji\n",
    "    text = remove_html_emoji(text)\n",
    "    # Remove stopwords\n",
    "    text = remove_stopwords(text)\n",
    "    # Lemmatize text\n",
    "    text_list = filter_text(text)\n",
    "    return text_list\n",
    "\n",
    "# Example\n",
    "preprocessor(df.loc[0, 'review'][-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "fb902a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [vote, grace, mark, carroll, screenplay, title...\n",
       "1    [watch, hour, kris, line, motion, holy, nonsen...\n",
       "2    [try, success, bruckheimer, jersey, script, ch...\n",
       "3    [watch, people, strutters, time, mirror, movie...\n",
       "4    [change, film, chorus, line, meaning, premise,...\n",
       "5    [plot, adult, history, ton, swim, ghost, year,...\n",
       "6    [liveliness, film, walk, backstage, doll, game...\n",
       "7    [line, course, tie, family, figuring, step, fr...\n",
       "8    [film, chavez, president, story, world, people...\n",
       "9    [place, film, walker, action, janine, mouse, r...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = df['review'].apply(preprocessor)\n",
    "\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab03833",
   "metadata": {},
   "source": [
    "# Create Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8ce77b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 area\n",
      "1 book\n",
      "2 brazil\n",
      "3 carroll\n",
      "4 case\n",
      "5 charge\n",
      "6 christopher\n",
      "7 class\n",
      "8 connecticut\n",
      "9 cover\n",
      "10 crime\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "# Create dictionary\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "8aa28ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out tokens that appear in\n",
    "\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100_000)\n",
    "\n",
    "# NOTE:\n",
    "# - Less than 15 documents (absolute number) or\n",
    "# - more than 0.5 documents (fraction of total corpus size, not absolute number)\n",
    "# - Keep only the first 100_000 most frequent tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c88bca",
   "metadata": {},
   "source": [
    "# Generate Model with Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "0140f458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 35 ('minute') appears 1\n",
      "Word 81 ('life') appears 1\n",
      "Word 123 ('video') appears 1\n",
      "Word 136 ('work') appears 1\n",
      "Word 234 ('daughter') appears 1\n",
      "Word 243 ('today') appears 1\n"
     ]
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "# Preview Bag of Words\n",
    "\n",
    "bow_doc_50 = bow_corpus[50]\n",
    "\n",
    "for i in range(len(bow_doc_50)):\n",
    "    print(f\"Word {bow_doc_50[i][0]} ('{dictionary[bow_doc_50[i][0]]}') appears {bow_doc_50[i][1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "6c7cb441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.017*\"time\" + 0.016*\"world\" + 0.015*\"character\" + 0.014*\"story\" + 0.012*\"year\" + 0.012*\"action\" + 0.012*\"people\" + 0.011*\"thing\" + 0.011*\"woman\" + 0.011*\"family\"\n",
      "Topic: 1 \n",
      "Words: 0.025*\"time\" + 0.016*\"story\" + 0.015*\"character\" + 0.013*\"plot\" + 0.013*\"scene\" + 0.012*\"year\" + 0.011*\"fact\" + 0.009*\"thing\" + 0.009*\"horror\" + 0.009*\"actor\"\n",
      "Topic: 2 \n",
      "Words: 0.034*\"character\" + 0.024*\"story\" + 0.021*\"time\" + 0.020*\"life\" + 0.017*\"thing\" + 0.016*\"people\" + 0.015*\"actor\" + 0.011*\"director\" + 0.011*\"role\" + 0.011*\"watch\"\n",
      "Topic: 3 \n",
      "Words: 0.023*\"year\" + 0.019*\"time\" + 0.017*\"actor\" + 0.013*\"scene\" + 0.013*\"kind\" + 0.012*\"people\" + 0.010*\"child\" + 0.010*\"role\" + 0.010*\"thing\" + 0.009*\"performance\"\n",
      "Topic: 4 \n",
      "Words: 0.031*\"time\" + 0.026*\"scene\" + 0.016*\"effect\" + 0.014*\"actor\" + 0.014*\"story\" + 0.014*\"director\" + 0.012*\"thing\" + 0.012*\"plot\" + 0.011*\"shot\" + 0.011*\"character\"\n",
      "Topic: 5 \n",
      "Words: 0.024*\"time\" + 0.021*\"story\" + 0.017*\"scene\" + 0.015*\"character\" + 0.014*\"moment\" + 0.013*\"play\" + 0.013*\"video\" + 0.012*\"watch\" + 0.011*\"look\" + 0.011*\"cast\"\n",
      "Topic: 6 \n",
      "Words: 0.026*\"time\" + 0.024*\"people\" + 0.019*\"story\" + 0.016*\"actor\" + 0.015*\"year\" + 0.014*\"plot\" + 0.014*\"scene\" + 0.012*\"role\" + 0.012*\"director\" + 0.012*\"watch\"\n",
      "Topic: 7 \n",
      "Words: 0.029*\"character\" + 0.021*\"time\" + 0.020*\"thing\" + 0.019*\"story\" + 0.018*\"scene\" + 0.016*\"year\" + 0.014*\"star\" + 0.014*\"actor\" + 0.014*\"life\" + 0.013*\"love\"\n",
      "Topic: 8 \n",
      "Words: 0.025*\"watch\" + 0.021*\"time\" + 0.021*\"character\" + 0.018*\"story\" + 0.016*\"scene\" + 0.014*\"action\" + 0.013*\"thing\" + 0.013*\"minute\" + 0.011*\"case\" + 0.011*\"plot\"\n",
      "Topic: 9 \n",
      "Words: 0.022*\"time\" + 0.021*\"life\" + 0.020*\"people\" + 0.019*\"work\" + 0.016*\"character\" + 0.016*\"story\" + 0.014*\"look\" + 0.013*\"comedy\" + 0.013*\"watch\" + 0.011*\"performance\"\n"
     ]
    }
   ],
   "source": [
    "lda_bow = gensim.models.LdaMulticore(bow_corpus,\n",
    "                                     num_topics=10,\n",
    "                                     id2word=dictionary,\n",
    "                                     passes=2, workers=2)\n",
    "\n",
    "# Print topic\n",
    "for idx, topic in lda_bow.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8f65e7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['work', 'workout', 'purchase', 'minute', 'blessing', 'easy', 'video', 'sweat', 'weight', 'exercise', 'today', 'circulation', 'pray', 'daughter', 'born', 'routine', 'channel', 'cable', 'life']\n",
      "\n",
      "Score: 0.8713967204093933\t \n",
      "Topic 7: \n",
      "0.029*\"character\" + 0.021*\"time\" + 0.020*\"thing\" + 0.019*\"story\" + 0.018*\"scene\" + 0.016*\"year\" + 0.014*\"star\" + 0.014*\"actor\" + 0.014*\"life\" + 0.013*\"love\"\n",
      "\n",
      "Score: 0.01429175678640604\t \n",
      "Topic 9: \n",
      "0.022*\"time\" + 0.021*\"life\" + 0.020*\"people\" + 0.019*\"work\" + 0.016*\"character\" + 0.016*\"story\" + 0.014*\"look\" + 0.013*\"comedy\" + 0.013*\"watch\" + 0.011*\"performance\"\n",
      "\n",
      "Score: 0.01428973488509655\t \n",
      "Topic 5: \n",
      "0.024*\"time\" + 0.021*\"story\" + 0.017*\"scene\" + 0.015*\"character\" + 0.014*\"moment\" + 0.013*\"play\" + 0.013*\"video\" + 0.012*\"watch\" + 0.011*\"look\" + 0.011*\"cast\"\n",
      "\n",
      "Score: 0.014289528131484985\t \n",
      "Topic 8: \n",
      "0.025*\"watch\" + 0.021*\"time\" + 0.021*\"character\" + 0.018*\"story\" + 0.016*\"scene\" + 0.014*\"action\" + 0.013*\"thing\" + 0.013*\"minute\" + 0.011*\"case\" + 0.011*\"plot\"\n",
      "\n",
      "Score: 0.0142893698066473\t \n",
      "Topic 6: \n",
      "0.026*\"time\" + 0.024*\"people\" + 0.019*\"story\" + 0.016*\"actor\" + 0.015*\"year\" + 0.014*\"plot\" + 0.014*\"scene\" + 0.012*\"role\" + 0.012*\"director\" + 0.012*\"watch\"\n",
      "\n",
      "Score: 0.01428885105997324\t \n",
      "Topic 2: \n",
      "0.034*\"character\" + 0.024*\"story\" + 0.021*\"time\" + 0.020*\"life\" + 0.017*\"thing\" + 0.016*\"people\" + 0.015*\"actor\" + 0.011*\"director\" + 0.011*\"role\" + 0.011*\"watch\"\n",
      "\n",
      "Score: 0.01428881473839283\t \n",
      "Topic 0: \n",
      "0.017*\"time\" + 0.016*\"world\" + 0.015*\"character\" + 0.014*\"story\" + 0.012*\"year\" + 0.012*\"action\" + 0.012*\"people\" + 0.011*\"thing\" + 0.011*\"woman\" + 0.011*\"family\"\n",
      "\n",
      "Score: 0.014288761653006077\t \n",
      "Topic 1: \n",
      "0.025*\"time\" + 0.016*\"story\" + 0.015*\"character\" + 0.013*\"plot\" + 0.013*\"scene\" + 0.012*\"year\" + 0.011*\"fact\" + 0.009*\"thing\" + 0.009*\"horror\" + 0.009*\"actor\"\n",
      "\n",
      "Score: 0.014288406819105148\t \n",
      "Topic 4: \n",
      "0.031*\"time\" + 0.026*\"scene\" + 0.016*\"effect\" + 0.014*\"actor\" + 0.014*\"story\" + 0.014*\"director\" + 0.012*\"thing\" + 0.012*\"plot\" + 0.011*\"shot\" + 0.011*\"character\"\n",
      "\n",
      "Score: 0.014288021251559258\t \n",
      "Topic 3: \n",
      "0.023*\"year\" + 0.019*\"time\" + 0.017*\"actor\" + 0.013*\"scene\" + 0.013*\"kind\" + 0.012*\"people\" + 0.010*\"child\" + 0.010*\"role\" + 0.010*\"thing\" + 0.009*\"performance\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try Model\n",
    "\n",
    "print(processed_docs[50])\n",
    "print()\n",
    "for idx, score in sorted(lda_bow[bow_corpus[50]],\n",
    "                         key=lambda tup: -1 * tup[1]):\n",
    "    print(f\"Score: {score}\\t \\nTopic {idx}: \\n{lda_bow.print_topic(idx, 10)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bfa418",
   "metadata": {},
   "source": [
    "# Generate Model with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4d5b82e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.23803442652931867),\n",
      " (1, 0.15734207500678157),\n",
      " (2, 0.16006211377497004),\n",
      " (3, 0.20380103752239218),\n",
      " (4, 0.24174948604559954),\n",
      " (5, 0.19297610351571345),\n",
      " (6, 0.17980319458648258),\n",
      " (7, 0.23803442652931867),\n",
      " (8, 0.21234460410405814),\n",
      " (9, 0.1361064882546078),\n",
      " (10, 0.1491046976763981),\n",
      " (11, 0.24174948604559954),\n",
      " (12, 0.16909050652408372),\n",
      " (13, 0.1981344879510331),\n",
      " (14, 0.1913544908305697),\n",
      " (15, 0.1522596485022355),\n",
      " (16, 0.1981344879510331),\n",
      " (17, 0.17724439806243122),\n",
      " (18, 0.14258110830068366),\n",
      " (19, 0.23454466453554773),\n",
      " (20, 0.1852895767384028),\n",
      " (21, 0.06667932243151192),\n",
      " (22, 0.24174948604559954),\n",
      " (23, 0.24174948604559954),\n",
      " (24, 0.18977731152742275),\n",
      " (25, 0.21970313316476817),\n",
      " (26, 0.09410216857912154)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "tfidf = gensim.models.TfidfModel(bow_corpus)\n",
    "tfidf_corpus = tfidf[bow_corpus]\n",
    "\n",
    "# Preview\n",
    "for doc in tfidf_corpus:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "fe48c2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.010*\"lot\" + 0.009*\"suit\" + 0.008*\"time\" + 0.008*\"night\" + 0.007*\"star\" + 0.007*\"comedy\" + 0.007*\"horror\" + 0.007*\"thing\" + 0.007*\"woman\" + 0.006*\"character\"\n",
      "Topic: 1 \n",
      "Words: 0.010*\"book\" + 0.009*\"change\" + 0.009*\"story\" + 0.009*\"love\" + 0.008*\"night\" + 0.008*\"family\" + 0.007*\"actor\" + 0.007*\"life\" + 0.007*\"joke\" + 0.007*\"character\"\n",
      "Topic: 2 \n",
      "Words: 0.009*\"scene\" + 0.009*\"plot\" + 0.009*\"minute\" + 0.009*\"surprise\" + 0.008*\"life\" + 0.008*\"effect\" + 0.008*\"recommend\" + 0.008*\"story\" + 0.008*\"problem\" + 0.008*\"time\"\n",
      "Topic: 3 \n",
      "Words: 0.010*\"story\" + 0.010*\"watch\" + 0.008*\"action\" + 0.008*\"series\" + 0.008*\"comedy\" + 0.008*\"thing\" + 0.008*\"character\" + 0.008*\"audience\" + 0.007*\"scene\" + 0.007*\"year\"\n",
      "Topic: 4 \n",
      "Words: 0.010*\"people\" + 0.009*\"watch\" + 0.009*\"plot\" + 0.009*\"john\" + 0.008*\"sense\" + 0.008*\"scene\" + 0.008*\"character\" + 0.007*\"time\" + 0.007*\"reason\" + 0.007*\"actor\"\n",
      "Topic: 5 \n",
      "Words: 0.010*\"direction\" + 0.010*\"script\" + 0.009*\"time\" + 0.009*\"scene\" + 0.009*\"parent\" + 0.008*\"director\" + 0.007*\"story\" + 0.007*\"character\" + 0.007*\"people\" + 0.007*\"hair\"\n",
      "Topic: 6 \n",
      "Words: 0.011*\"time\" + 0.009*\"actor\" + 0.009*\"star\" + 0.008*\"plot\" + 0.008*\"mark\" + 0.008*\"thing\" + 0.008*\"experience\" + 0.008*\"world\" + 0.008*\"action\" + 0.007*\"director\"\n",
      "Topic: 7 \n",
      "Words: 0.010*\"watch\" + 0.009*\"character\" + 0.008*\"waste\" + 0.008*\"time\" + 0.008*\"story\" + 0.008*\"scene\" + 0.008*\"line\" + 0.008*\"look\" + 0.008*\"reason\" + 0.008*\"moment\"\n",
      "Topic: 8 \n",
      "Words: 0.011*\"year\" + 0.010*\"actor\" + 0.010*\"people\" + 0.009*\"person\" + 0.009*\"story\" + 0.008*\"time\" + 0.008*\"hour\" + 0.008*\"character\" + 0.008*\"place\" + 0.007*\"play\"\n",
      "Topic: 9 \n",
      "Words: 0.009*\"manner\" + 0.009*\"work\" + 0.009*\"life\" + 0.008*\"production\" + 0.008*\"director\" + 0.008*\"people\" + 0.008*\"play\" + 0.007*\"character\" + 0.007*\"actor\" + 0.007*\"chance\"\n"
     ]
    }
   ],
   "source": [
    "lda_tfidf = gensim.models.LdaMulticore(tfidf_corpus, num_topics=10,\n",
    "                                      id2word=dictionary, passes=2,\n",
    "                                      workers=4)\n",
    "\n",
    "# Print topic\n",
    "for idx, topic in lda_tfidf.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "07458212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['work', 'workout', 'purchase', 'minute', 'blessing', 'easy', 'video', 'sweat', 'weight', 'exercise', 'today', 'circulation', 'pray', 'daughter', 'born', 'routine', 'channel', 'cable', 'life']\n",
      "\n",
      "Score: 0.8713927865028381\t \n",
      "Topic 9: \n",
      "0.009*\"manner\" + 0.009*\"work\" + 0.009*\"life\" + 0.008*\"production\" + 0.008*\"director\" + 0.008*\"people\" + 0.008*\"play\" + 0.007*\"character\" + 0.007*\"actor\" + 0.007*\"chance\"\n",
      "\n",
      "Score: 0.014291995204985142\t \n",
      "Topic 2: \n",
      "0.009*\"scene\" + 0.009*\"plot\" + 0.009*\"minute\" + 0.009*\"surprise\" + 0.008*\"life\" + 0.008*\"effect\" + 0.008*\"recommend\" + 0.008*\"story\" + 0.008*\"problem\" + 0.008*\"time\"\n",
      "\n",
      "Score: 0.014291148632764816\t \n",
      "Topic 7: \n",
      "0.010*\"watch\" + 0.009*\"character\" + 0.008*\"waste\" + 0.008*\"time\" + 0.008*\"story\" + 0.008*\"scene\" + 0.008*\"line\" + 0.008*\"look\" + 0.008*\"reason\" + 0.008*\"moment\"\n",
      "\n",
      "Score: 0.014290020801126957\t \n",
      "Topic 8: \n",
      "0.011*\"year\" + 0.010*\"actor\" + 0.010*\"people\" + 0.009*\"person\" + 0.009*\"story\" + 0.008*\"time\" + 0.008*\"hour\" + 0.008*\"character\" + 0.008*\"place\" + 0.007*\"play\"\n",
      "\n",
      "Score: 0.014290005899965763\t \n",
      "Topic 1: \n",
      "0.010*\"book\" + 0.009*\"change\" + 0.009*\"story\" + 0.009*\"love\" + 0.008*\"night\" + 0.008*\"family\" + 0.007*\"actor\" + 0.007*\"life\" + 0.007*\"joke\" + 0.007*\"character\"\n",
      "\n",
      "Score: 0.014289183542132378\t \n",
      "Topic 0: \n",
      "0.010*\"lot\" + 0.009*\"suit\" + 0.008*\"time\" + 0.008*\"night\" + 0.007*\"star\" + 0.007*\"comedy\" + 0.007*\"horror\" + 0.007*\"thing\" + 0.007*\"woman\" + 0.006*\"character\"\n",
      "\n",
      "Score: 0.014288855716586113\t \n",
      "Topic 4: \n",
      "0.010*\"people\" + 0.009*\"watch\" + 0.009*\"plot\" + 0.009*\"john\" + 0.008*\"sense\" + 0.008*\"scene\" + 0.008*\"character\" + 0.007*\"time\" + 0.007*\"reason\" + 0.007*\"actor\"\n",
      "\n",
      "Score: 0.014288825914263725\t \n",
      "Topic 5: \n",
      "0.010*\"direction\" + 0.010*\"script\" + 0.009*\"time\" + 0.009*\"scene\" + 0.009*\"parent\" + 0.008*\"director\" + 0.007*\"story\" + 0.007*\"character\" + 0.007*\"people\" + 0.007*\"hair\"\n",
      "\n",
      "Score: 0.014288755133748055\t \n",
      "Topic 6: \n",
      "0.011*\"time\" + 0.009*\"actor\" + 0.009*\"star\" + 0.008*\"plot\" + 0.008*\"mark\" + 0.008*\"thing\" + 0.008*\"experience\" + 0.008*\"world\" + 0.008*\"action\" + 0.007*\"director\"\n",
      "\n",
      "Score: 0.014288431033492088\t \n",
      "Topic 3: \n",
      "0.010*\"story\" + 0.010*\"watch\" + 0.008*\"action\" + 0.008*\"series\" + 0.008*\"comedy\" + 0.008*\"thing\" + 0.008*\"character\" + 0.008*\"audience\" + 0.007*\"scene\" + 0.007*\"year\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try Model\n",
    "\n",
    "print(processed_docs[50])\n",
    "print()\n",
    "for idx, score in sorted(lda_tfidf[bow_corpus[50]],\n",
    "                         key=lambda tup: -1 * tup[1]):\n",
    "    print(f\"Score: {score}\\t \\nTopic {idx}: \\n{lda_tfidf.print_topic(idx, 10)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2f9d73",
   "metadata": {},
   "source": [
    "# Compute Model Perplexity and Coherence Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "920de796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -6.3012268998269905\n",
      "\n",
      "Coherence Score:  0.32062085403895685\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_bow.log_perplexity(bow_corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_bow = CoherenceModel(model=lda_bow, texts=processed_docs.values,\n",
    "                                     dictionary=dictionary, coherence='c_v')\n",
    "coherence_bow = coherence_model_bow.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "51436e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -8.115745296839096\n",
      "\n",
      "Coherence Score:  0.2823989186474825\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_tfidf.log_perplexity(tfidf_corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_tfidf = CoherenceModel(model=lda_tfidf, texts=processed_docs.values,\n",
    "                                     dictionary=dictionary, coherence='c_v')\n",
    "coherence_tfidf = coherence_model_tfidf.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768d28cc",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5dc01303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimum_lda(dictionary, corpus, texts, limit,\n",
    "                    start=2, step=1, get_result=False):\n",
    "    coherence_values = []\n",
    "    \n",
    "    for n in range(start, limit, step):\n",
    "        lda = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                         num_topics=n,\n",
    "                                         id2word=dictionary)\n",
    "        \n",
    "        # Create coherence\n",
    "        coherence_model = CoherenceModel(model=lda, \n",
    "                                         texts=texts,\n",
    "                                         dictionary=dictionary, \n",
    "                                         coherence='c_v')\n",
    "        coherence_values.append(coherence_model.get_coherence())\n",
    "#         print(f\"Idx {n} {coherence_model.get_coherence()}\")\n",
    "    \n",
    "    \n",
    "    opt_num_topics = start + coherence_values.index(max(coherence_values))\n",
    "    \n",
    "    lda_opt = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                         num_topics=opt_num_topics,\n",
    "                                         id2word=dictionary)\n",
    "    \n",
    "    if get_result:\n",
    "        print(coherence_values)\n",
    "    \n",
    "    return lda_opt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "77bcdf85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.335416263411897, 0.33292674568743263, 0.3237980748399089, 0.33074832788538644, 0.3207986336690229, 0.3255201381235756, 0.3283921503793936, 0.3270229709566922]\n",
      "Topic: 0 \n",
      "Words: 0.025*\"time\" + 0.017*\"character\" + 0.017*\"story\" + 0.017*\"scene\" + 0.014*\"actor\" + 0.013*\"thing\" + 0.012*\"life\" + 0.011*\"plot\" + 0.011*\"people\" + 0.010*\"watch\"\n",
      "Topic: 1 \n",
      "Words: 0.021*\"time\" + 0.019*\"character\" + 0.019*\"story\" + 0.015*\"people\" + 0.013*\"year\" + 0.012*\"thing\" + 0.012*\"scene\" + 0.011*\"director\" + 0.011*\"life\" + 0.010*\"watch\"\n"
     ]
    }
   ],
   "source": [
    "lda_opt_bow = get_optimum_lda(dictionary, bow_corpus,\n",
    "                              processed_docs.values,\n",
    "                              10, get_result=True)\n",
    "\n",
    "# Print topic\n",
    "for idx, topic in lda_opt_bow.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "f28da1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31333278371885903, 0.29888059485296486, 0.32294370584400506, 0.2886353863454591, 0.3160182194573718, 0.30392786395057253, 0.30562898273690253, 0.3114187071451975]\n",
      "Topic: 0 \n",
      "Words: 0.009*\"watch\" + 0.009*\"scene\" + 0.008*\"character\" + 0.007*\"year\" + 0.007*\"time\" + 0.007*\"music\" + 0.007*\"thing\" + 0.007*\"work\" + 0.007*\"people\" + 0.006*\"life\"\n",
      "Topic: 1 \n",
      "Words: 0.009*\"life\" + 0.008*\"plot\" + 0.008*\"thing\" + 0.008*\"time\" + 0.008*\"story\" + 0.007*\"actor\" + 0.007*\"role\" + 0.007*\"scene\" + 0.007*\"performance\" + 0.007*\"watch\"\n",
      "Topic: 2 \n",
      "Words: 0.009*\"family\" + 0.008*\"horror\" + 0.008*\"time\" + 0.008*\"story\" + 0.007*\"character\" + 0.007*\"watch\" + 0.007*\"actor\" + 0.007*\"effect\" + 0.007*\"line\" + 0.007*\"people\"\n",
      "Topic: 3 \n",
      "Words: 0.009*\"story\" + 0.009*\"people\" + 0.008*\"actor\" + 0.008*\"time\" + 0.008*\"character\" + 0.007*\"scene\" + 0.006*\"look\" + 0.006*\"plot\" + 0.006*\"world\" + 0.006*\"thing\"\n"
     ]
    }
   ],
   "source": [
    "lda_opt_tfidf = get_optimum_lda(dictionary, tfidf_corpus,\n",
    "                                  processed_docs.values,\n",
    "                                  10, get_result=True)\n",
    "\n",
    "# Print topic\n",
    "for idx, topic in lda_opt_tfidf.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5042b3bd",
   "metadata": {},
   "source": [
    "# Labeling Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "6a77b9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_test['review'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "641ddb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_topic(text):\n",
    "    text = preprocessor(text)\n",
    "    bow_vector = dictionary.doc2bow(text)\n",
    "    \n",
    "    result = sorted(lda_opt_tfidf[bow_vector], \n",
    "                    key=lambda x: -1*x[1])[0][0]\n",
    "    \n",
    "    return result\n",
    "    \n",
    "# Extract keywords into a dictionary or list\n",
    "topics_dict = {}\n",
    "for topic_num, topic in lda_opt_tfidf.show_topics(num_topics=10,\n",
    "                                                num_words=10,\n",
    "                                                formatted=False):\n",
    "    keywords = [word for word, _ in topic]\n",
    "    topics_dict[topic_num] = keywords\n",
    "\n",
    "df_test['topic'] = df_test['review'].apply(predict_topic)\n",
    "df_test['key_topic'] = df_test['topic'].apply(lambda x: topics_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "41e37d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>topic</th>\n",
       "      <th>key_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>I'd have little to add to bowlofsoul23's bull'...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[watch, scene, character, year, time, music, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>We just saw this film previewed before release...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[life, plot, thing, time, story, actor, role, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>After reading more than my fair share of revie...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[watch, scene, character, year, time, music, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>I awake suddenly, aware that I'm drooling onto...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[family, horror, time, story, character, watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>The 700 Club gives a great perspective on worl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[watch, scene, character, year, time, music, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>I was expecting this to be just like the other...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[watch, scene, character, year, time, music, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>...........as I was when I saw this movie) I w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[watch, scene, character, year, time, music, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Has anyone found a way to purchase copies of t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[watch, scene, character, year, time, music, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Perhaps once in a generation a film comes alon...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[watch, scene, character, year, time, music, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Quite simply the best reality show ever made. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[watch, scene, character, year, time, music, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  sentiment  topic  \\\n",
       "1001  I'd have little to add to bowlofsoul23's bull'...          0      0   \n",
       "1002  We just saw this film previewed before release...          1      1   \n",
       "1003  After reading more than my fair share of revie...          1      0   \n",
       "1004  I awake suddenly, aware that I'm drooling onto...          0      2   \n",
       "1005  The 700 Club gives a great perspective on worl...          1      0   \n",
       "...                                                 ...        ...    ...   \n",
       "1995  I was expecting this to be just like the other...          1      0   \n",
       "1996  ...........as I was when I saw this movie) I w...          1      0   \n",
       "1997  Has anyone found a way to purchase copies of t...          1      0   \n",
       "1998  Perhaps once in a generation a film comes alon...          1      0   \n",
       "1999  Quite simply the best reality show ever made. ...          1      0   \n",
       "\n",
       "                                              key_topic  \n",
       "1001  [watch, scene, character, year, time, music, t...  \n",
       "1002  [life, plot, thing, time, story, actor, role, ...  \n",
       "1003  [watch, scene, character, year, time, music, t...  \n",
       "1004  [family, horror, time, story, character, watch...  \n",
       "1005  [watch, scene, character, year, time, music, t...  \n",
       "...                                                 ...  \n",
       "1995  [watch, scene, character, year, time, music, t...  \n",
       "1996  [watch, scene, character, year, time, music, t...  \n",
       "1997  [watch, scene, character, year, time, music, t...  \n",
       "1998  [watch, scene, character, year, time, music, t...  \n",
       "1999  [watch, scene, character, year, time, music, t...  \n",
       "\n",
       "[999 rows x 4 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "b2e9f3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    317\n",
       "1    316\n",
       "3    233\n",
       "2    133\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162c662f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
