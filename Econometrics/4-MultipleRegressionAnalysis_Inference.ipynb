{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8402e632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baha Tegar\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Import package for getting dataset example\n",
    "import wooldridge as woo\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85e2718",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "### Classical Linear Model (CLM) Assumptions\n",
    "\n",
    "1. The true model follows:\n",
    "> $$\n",
    "y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\cdots + \\beta_k x_k + \\text{e}\n",
    "$$\n",
    "\n",
    "\n",
    "2. There are random sample of n observations from population {$(x_{i,1}, x_{i,2}, ..., x_{i,k}, y_i) : i = 1, 2, 3, ..., n$}\n",
    "\n",
    "3. No perfect collinearity \n",
    "> It allows the regressors to be correlated, they just cannot be perfectly linear correlated.\n",
    "\n",
    "4. Zero conditional mean\n",
    "> The error term $\\text{e}$ has an expected value of zero given any values of the regressors:\n",
    "> $$ E (e | x_1, x_2, ..., x_k) = 0 $$\n",
    "\n",
    "5. Homoskedasticity (**It doesn't make the estomator bias**, but it makes less precise estimator and less accurate hypothesis tests)\n",
    "> $$ Var(e | x_1, x_2, ..., x_k) = \\sigma $$\n",
    "\n",
    "6. Normality (**It doesn't make the estimator being bias**, it makes the sampling distributions of the estimator $\\hat{\\beta}_j$ traceable)\n",
    "> The population error $\\text{e}$ is independent of the explanatory variables $x_1, x_2, \\dots, x_k$ and is normally distributed with $\\text{e} \\sim \\text{Normal}(0, \\sigma^2)$\n",
    "\n",
    "NOTE:\n",
    "- It very often happens that the error term from regression model have a distribution that is not excessively skewed and with no outliers.\n",
    "- If the model is homoskedasticity, then the Central Limit Theorem (CLM) ensures that the error term asymptotically normal when the sample is large enough (commonly minimum 30 size samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe21f084",
   "metadata": {},
   "source": [
    "### Theorem: Normal Sampling Distributions\n",
    "> Under the CLM assumptions, conditional on the sample values of the independent variables,\n",
    "$$\n",
    "\\hat{\\beta}_{j} \\sim \\text{Normal}(\\beta_{j}, \\text{Var}(\\hat{\\beta}_{j}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14c5c57",
   "metadata": {},
   "source": [
    "# The t-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68efbf",
   "metadata": {},
   "source": [
    "![image](images/4_t-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ac9e44",
   "metadata": {},
   "source": [
    "![image](images/4_t-table1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb35fc5",
   "metadata": {},
   "source": [
    "![image](images/4_t-table2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af491002",
   "metadata": {},
   "source": [
    "### Confidence Interval\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_j \\pm \\text{t}_{crit} \\text{se}({\\hat{\\beta}_j})\n",
    "$$\n",
    "\n",
    "where,\n",
    "- $ \\text{se}(\\hat{\\beta}_j) = \\frac{\\hat{\\sigma}_{rg}}{\\sqrt{n} \\sqrt{1 - R_j^2} \\, sd(x_j)} $\n",
    "- $sd(x_j) = \\sqrt{1/n \\sum_{i=1}^{n} (x_{i, j} - \\bar{x})^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e74e58",
   "metadata": {},
   "source": [
    "### Case Estimating t-value and p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b06eef1",
   "metadata": {},
   "source": [
    "![image](images/Example_4-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cef1b44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           np.log(wage)   R-squared:                       0.316\n",
      "Model:                            OLS   Adj. R-squared:                  0.312\n",
      "Method:                 Least Squares   F-statistic:                     80.39\n",
      "Date:                Sat, 31 Aug 2024   Prob (F-statistic):           9.13e-43\n",
      "Time:                        16:12:26   Log-Likelihood:                -313.55\n",
      "No. Observations:                 526   AIC:                             635.1\n",
      "Df Residuals:                     522   BIC:                             652.2\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.2844      0.104      2.729      0.007       0.080       0.489\n",
      "educ           0.0920      0.007     12.555      0.000       0.078       0.106\n",
      "exper          0.0041      0.002      2.391      0.017       0.001       0.008\n",
      "tenure         0.0221      0.003      7.133      0.000       0.016       0.028\n",
      "==============================================================================\n",
      "Omnibus:                       11.534   Durbin-Watson:                   1.769\n",
      "Prob(Omnibus):                  0.003   Jarque-Bera (JB):               20.941\n",
      "Skew:                           0.021   Prob(JB):                     2.84e-05\n",
      "Kurtosis:                       3.977   Cond. No.                         135.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Using summary model\n",
    "wage1 = woo.dataWoo('wage1')\n",
    "\n",
    "model = smf.ols(formula='np.log(wage) ~ educ + exper + tenure', data=wage1).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "415ce43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta: \n",
      "{'intercept': 0.2843595552360746, 'educ': 0.0920289867692827, 'exper': 0.004121109045609959, 'tenure': 0.022067217434724347}\n",
      "Std Error Params: \n",
      " {'intercept': 0.10419037797067718, 'educ': 0.0073299232744946695, 'exper': 0.0017232772008454382, 'tenure': 0.0030936491910178287}\n",
      "t-values:\n",
      " {'intercept': 2.7292304795756026, 'educ': 12.555245576649948, 'exper': 2.3914371080799692, 'tenure': 7.133070387810876}\n",
      "p-values:\n",
      " {'intercept': 0.006562462394036572, 'educ': 0.0, 'exper': 0.01713562312471195, 'tenure': 3.2944758032726895e-12}\n"
     ]
    }
   ],
   "source": [
    "# Calculating manual (This model assume it's two-tail hypothesis testing)\n",
    "\n",
    "regressors = ['educ', 'exper', 'tenure']\n",
    "target = 'wage'\n",
    "n = int(wage1.shape[0])\n",
    "df = n - len(regressors) - 1\n",
    "\n",
    "params = {}\n",
    "se_params = {}\n",
    "t_values = {}\n",
    "p_values = {}\n",
    "\n",
    "# Extract X and y\n",
    "X = pd.DataFrame(np.ones(n, dtype=int))\n",
    "X = pd.concat([X, wage1[regressors]], axis=1)\n",
    "y = wage1[target].apply(lambda x: np.log(x))\n",
    "\n",
    "# Parameters estimates\n",
    "X = np.array(X)\n",
    "y = np.array(y).reshape(n, 1)\n",
    "b = np.linalg.inv(X.T@X) @ X.T @ y\n",
    "\n",
    "# Store params\n",
    "for i in range(b.shape[0]):\n",
    "    if i == 0:\n",
    "        params['intercept'] = b[i, 0]\n",
    "    else:\n",
    "        params[f'{regressors[i - 1]}'] = b[i, 0]\n",
    "print(f\"Beta: \\n{params}\")\n",
    "\n",
    "# Residuals, estiamted variance of residuals and SER\n",
    "residuals = y - X @ b\n",
    "var_residuals = (residuals.T @ residuals) / df\n",
    "SER = np.sqrt(var_residuals)[0][0]\n",
    "\n",
    "# Estimated variance of the parameters estiamtors and SE\n",
    "var_beta = var_residuals * np.linalg.inv(X.T @ X)\n",
    "std_error_beta = np.sqrt(np.diagonal(var_beta))\n",
    "\n",
    "# Store std error beta\n",
    "for i in range(len(std_error_beta)):\n",
    "    if i == 0:\n",
    "        se_params['intercept'] = std_error_beta[i]\n",
    "    else:\n",
    "        se_params[f'{regressors[i - 1]}'] = std_error_beta[i]\n",
    "    \n",
    "print(f\"Std Error Params: \\n\", se_params)\n",
    "\n",
    "# Regressors\n",
    "for variable in ['intercept'] + regressors:\n",
    "    t_value_temp = params[f'{variable}'] / se_params[f\"{variable}\"]\n",
    "    t_values[f'{variable}'] = t_value_temp\n",
    "    p_values[f'{variable}'] = 2 * (1 - stats.t.cdf(t_value_temp, df))\n",
    "    \n",
    "    \n",
    "print(\"t-values:\\n\", t_values)\n",
    "print(\"p-values:\\n\", p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd852504",
   "metadata": {},
   "source": [
    "### Case Confidence Interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5f62a2",
   "metadata": {},
   "source": [
    "![image](images/Example_4-8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dde1b584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             np.log(rd)   R-squared:                       0.918\n",
      "Model:                            OLS   Adj. R-squared:                  0.912\n",
      "Method:                 Least Squares   F-statistic:                     162.2\n",
      "Date:                Sun, 01 Sep 2024   Prob (F-statistic):           1.79e-16\n",
      "Time:                        00:11:07   Log-Likelihood:                -22.511\n",
      "No. Observations:                  32   AIC:                             51.02\n",
      "Df Residuals:                      29   BIC:                             55.42\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept        -4.3783      0.468     -9.355      0.000      -5.335      -3.421\n",
      "np.log(sales)     1.0842      0.060     18.012      0.000       0.961       1.207\n",
      "profmarg          0.0217      0.013      1.694      0.101      -0.004       0.048\n",
      "==============================================================================\n",
      "Omnibus:                        0.670   Durbin-Watson:                   1.859\n",
      "Prob(Omnibus):                  0.715   Jarque-Bera (JB):                0.671\n",
      "Skew:                           0.308   Prob(JB):                        0.715\n",
      "Kurtosis:                       2.649   Cond. No.                         70.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "rdchem = woo.dataWoo('rdchem')\n",
    "model = smf.ols(formula='np.log(rd) ~ np.log(sales) + profmarg', data=rdchem).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6f8818d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.05: {'intercept': (-5.335478449854297, -3.421068063286227), 'sales': (0.9611072560097991, 1.2073324801318692), 'profmarg': (-0.004487721638015394, 0.04779910329394195)}, 0.01: {'intercept': (-5.668312696315954, -3.0882338168245704), 'sales': (0.9182992000644719, 1.2501405360771964), 'profmarg': (-0.013578168544385521, 0.05688955020031207)}}\n"
     ]
    }
   ],
   "source": [
    "# Calculate manual\n",
    "\n",
    "rdchem = woo.dataWoo('rdchem')\n",
    "regressors = ['sales', 'profmarg']\n",
    "target = 'rd'\n",
    "n = rdchem.shape[0]\n",
    "df = n - len(regressors) - 1\n",
    "alpha = np.array([0.05, 0.01])\n",
    "\n",
    "# Storage\n",
    "params = {}\n",
    "se_params = {}\n",
    "CI_params = {}\n",
    "\n",
    "\n",
    "# Calculate critical values\n",
    "c_values = stats.t.ppf(1 - alpha / 2, df)\n",
    "\n",
    "# Extract X and y\n",
    "X = pd.DataFrame(np.ones(n, dtype=int))\n",
    "X = pd.concat([X, rdchem[regressors]], axis=1)\n",
    "X['sales'] = X['sales'].apply(lambda x: np.log(x))\n",
    "\n",
    "y = rdchem[target].apply(lambda x: np.log(x))\n",
    "\n",
    "# Parameters estimates\n",
    "X = np.array(X)\n",
    "y = np.array(y).reshape(-1, 1)\n",
    "b = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "# Store params\n",
    "for i in range(b.shape[0]):\n",
    "    if i == 0:\n",
    "        params['intercept'] = b[i, 0]\n",
    "    else:\n",
    "        params[f'{regressors[i - 1]}'] = b[i, 0]\n",
    "\n",
    "# Estimate std error parameters\n",
    "residuals = y - X @ b\n",
    "var_residuals = (residuals.T @ residuals) / df\n",
    "var_beta = var_residuals * np.linalg.inv(X.T @ X)\n",
    "std_error_beta = np.sqrt(np.diagonal(var_beta))\n",
    "\n",
    "# Store std error beta\n",
    "for i in range(len(std_error_beta)):\n",
    "    if i == 0:\n",
    "        se_params['intercept'] = std_error_beta[i]\n",
    "    else:\n",
    "        se_params[f'{regressors[i - 1]}'] = std_error_beta[i]\n",
    "\n",
    "# Calculate Confidence Interval\n",
    "for i in range(len(c_values)):\n",
    "    temp = {}\n",
    "    c = c_values[i]\n",
    "    for v in ['intercept'] + regressors:\n",
    "        temp[v] = (params[v] - c * se_params[v], params[v] + c * se_params[v])\n",
    "    CI_params[alpha[i]] = temp\n",
    "\n",
    "print(CI_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2d5127",
   "metadata": {},
   "source": [
    "# The F-Test \n",
    "> It usually used for testing multiple linear regression. \n",
    "\n",
    "NOTE: In this case, we use Right-tailed test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3016783",
   "metadata": {},
   "source": [
    "**Define Problem**\n",
    "\n",
    "Let we define:\n",
    "- Unrestricted model with $k$ independent: $y_{ur} = \\beta^{ur}_{0} + \\beta^{ur}_{1}x_1 + \\dots + \\beta^{ur}_{k}x_k + e_{ur}$\n",
    "- Restricted model with $q$ exclusion restrictions: $y_{r} = \\beta^{r}_{0} + \\beta^{r}_{1}x_1 + \\dots + \\beta^{r}_{k-q}x_{k-q} + e_{r}$ \n",
    "\n",
    "Then we have F statistic:\n",
    "$$\n",
    "F \\equiv \\frac{(SSR_r - SSR_{ur}) / q}{SSR_{ur} / (n - k - 1)}\n",
    "$$\n",
    "\n",
    "where,\n",
    "- $SSR_r = \\text{Sum of Square Residuals Restricted Model}$ \n",
    "- $SSR_{ur} = \\text{Sum of Square Residuals Unrestricted Model}$\n",
    "- $q = df_r - df_{ur}$\n",
    "- $df_r = \\text{Degrees of Freedom Restricted Model}$\n",
    "- $df_{ur} = \\text{Degrees of Freedom Unrestricted Model}$ \n",
    "- $n = \\text{Number of observations}$ \n",
    "- $k = \\text{Number of regressors}$\n",
    "\n",
    "\n",
    "NOTE:\n",
    "- $SSR_r \\ge SSR_{ur}$ it means the results never negative. The minimum result is zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfc671e",
   "metadata": {},
   "source": [
    "**Hypothesis Testing**\n",
    "\n",
    "![image](images/4_f-table1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09098a8e",
   "metadata": {},
   "source": [
    "### Case\n",
    "- Unrestricted model:\n",
    "> np.log(salary) = years + gamesyr + bavg +  hrunsyr + rbisyr + $e_{ur}$\n",
    "- Restricted model:\n",
    "> np.log(salary) = years + gamesyr + $e_r$\n",
    "\n",
    "- Restricted regressors: bavg, hrunsyr, rbisyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ff99557a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_score: 9.55\n",
      "F_critical: 3.839\n",
      "F_score > F_critical = True\n",
      "\n",
      "p-value: 0.0\n",
      "alpha: 0.01\n",
      "p_value <= alpha = True\n"
     ]
    }
   ],
   "source": [
    "mlb1 = woo.dataWoo('mlb1')\n",
    "n = mlb1.shape[0]\n",
    "q = 3\n",
    "alpha = .01\n",
    "\n",
    "# unrestricted OLS regression\n",
    "model_ur = smf.ols(formula='np.log(salary) ~ years + gamesyr + bavg + hrunsyr + rbisyr', \n",
    "                   data=mlb1).fit()\n",
    "\n",
    "ssr_ur = np.sum(np.power(model_ur.resid, 2))\n",
    "\n",
    "# restricted OLS regression\n",
    "model_r = smf.ols(formula='np.log(salary) ~ years + gamesyr',\n",
    "                   data=mlb1).fit()\n",
    "ssr_r = np.sum(np.power(model_r.resid, 2))\n",
    "\n",
    "# F-testing\n",
    "F_score = (ssr_r - ssr_ur) / ssr_ur * (n - 5 - 1) / (q)\n",
    "F_critical = stats.f.ppf(1 - alpha, q, n - 5 - 1)\n",
    "print(f\"F_score: {round(F_score, 3)}\")\n",
    "print(f\"F_critical: {round(F_critical, 3)}\")\n",
    "print(f\"F_score > F_critical = {F_score > F_critical}\\n\")\n",
    "\n",
    "# P-value\n",
    "p_value = 1 - stats.f.cdf(F_score, q, n - 5 - 1)\n",
    "print(f\"p-value: {round(p_value, 3)}\")\n",
    "print(f\"alpha: {alpha}\")\n",
    "print(f\"p_value <= alpha = {p_value < alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b494df24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fstat: 9.550253521951765\n",
      "\n",
      "fpval: 4.47370813983966e-06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using built in package \"automatic\"\n",
    "\n",
    "mlb1 = woo.dataWoo('mlb1')\n",
    "\n",
    "# OLS regression\n",
    "model = smf.ols(formula='np.log(salary) ~ years + gamesyr + bavg + hrunsyr + rbisyr',\n",
    "               data=mlb1).fit()\n",
    "\n",
    "# Automated F test:\n",
    "hypotheses = ['bavg = 0', 'hrunsyr = 0', 'rbisyr = 0']\n",
    "ftest = model.f_test(hypotheses)\n",
    "fstat = ftest.statistic\n",
    "fpval = ftest.pvalue\n",
    "\n",
    "print(f'fstat: {fstat}\\n')\n",
    "print(f'fpval: {fpval}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
