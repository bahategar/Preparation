{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a884968e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baha Tegar\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Import package for getting dataset example\n",
    "import wooldridge as woo\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ea8907",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "> Recall that if homoscedasticity is violated, the standard errors are invalid and all inferences from t, F, and other test based on them are unreliable. Also the asymptotic of OLS depends on homoscedasticity.\n",
    "\n",
    "This is the flow chart how to deal with heteroscedasticity:\n",
    "\n",
    "1. Heteroscedasticity Tests.\n",
    "2. If it's heteroscedasity, then try fit model with Weighted Least Squares (WLS) instead OLS.\n",
    "3. Do Heteroscedasticity Test on WLS model.\n",
    "4. If it's heteroscedasity, then try develop Heteroscedasticity-robust statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3864016",
   "metadata": {},
   "source": [
    "# Heteroscedasticity Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e56465",
   "metadata": {},
   "source": [
    "# Heteroscedasticity-Robust Statistics\n",
    "\n",
    "> Heteroscedasticity-Robust statistics will modify the standard errors of the regression coefficients so that the hypothesis tests and confidence intervals remain valid even when heteroskedasticity is present.\n",
    "\n",
    "Here are a few key points about heteroskedasticity-robust statistics:\n",
    "\n",
    "- Robust Standard Errors: These are adjusted standard errors that account for heteroskedasticity. They provide more reliable estimates of the variability of the regression coefficients when the error variance is not constant.\n",
    "\n",
    "- Robust Variance-Covariance Matrix: The matrix of the parameter estimates' variances and covariances is adjusted to be robust to heteroskedasticity. This adjustment leads to more accurate inference in the presence of heteroskedasticity.\n",
    "\n",
    "- White's Standard Errors: Named after Halbert White, these are a common type of heteroskedasticity-robust standard errors. They provide a way to correct the standard errors for heteroskedasticity without requiring a specific model for the error variance.\n",
    "\n",
    "- Cluster-Robust Standard Errors: When data is grouped into clusters (e.g., students within schools, patients within hospitals), cluster-robust standard errors account for the fact that observations within the same cluster may be correlated. This is useful when heteroskedasticity is present and observations are not independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d79a918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
